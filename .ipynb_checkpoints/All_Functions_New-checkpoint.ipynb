{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "import copy\n",
    "import operator\n",
    "import glob\n",
    "#import pprint\n",
    "import argparse\n",
    "import datetime\n",
    "import queue\n",
    "import multiprocessing\n",
    "from alive_progress import alive_bar\n",
    "import numpy.matlib\n",
    "import numpy as np     # For Mathmatical (Algebra) Operation\n",
    "from sys import platform   # To verify the Operating Sys Win or Linux\n",
    "from Bio import SeqIO  # For Bio Python Sequence Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Blastp = /usr/bin/blastp\n",
    "Blastp = \"blastp\"\n",
    "Blastp_data =  './blastp_data/'\n",
    "cpu_count = 1 # Default value\n",
    "blastp_matrix = \"BLOSUM62\" \n",
    "genome = \"\"\n",
    "infinite_loop = 70\n",
    "inflation_factor = 1.4\n",
    "#mode = None\n",
    "mode = '1' #Change Later\n",
    "Cluster_out = \"./cluster_out/\"\n",
    "#threshold_score : 0\n",
    "threshold_score =0\n",
    "Save_raw_blastp_score = False\n",
    "Score_file = \"./score_file\"\n",
    "Species = \"./species/\"\n",
    "species = \"./species/\"\n",
    "verbose = False\n",
    "Log_file_name = \"log_files/\"\n",
    "save_raw_blastp_score = \"score_file/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1. Matrix_Name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Matrix_Name():\n",
    "    \"\"\"This Function will Return the Matrix name choosed by User.\n",
    "    BLOSUM45 ,  BLOSUM62 , BLOSUM82 \"\"\"\n",
    "    print(\"BLOcks SUbstitution Matrix (BLOSUM) is a Substitution matrix used for sequence alignment of Proteins\")\n",
    "    print(\"\"\"\\n1. BLOSUM45 :-For more distantly related Proteins alignment DataBase\\n2. BLOSUM62 :- MidRange Seq with more than 62%similarity\\\n",
    "         \\n3. BLOSUM82 :- More related Proteins\\nOther Keys to exit the Program -- Quit\"\"\")\n",
    "    metrix_num = input(\"\\nEnter a matrix number: \")\n",
    "    if metrix_num not in (\"1\", \"2\", '3'):\n",
    "        print(\"Wrong input *%s*Sorry not in list\\n\" %\n",
    "              metrix_num, \"*\"*20, \"Good Bye\", \"*\"*20, \"\\n\")\n",
    "        sys.exit(1)\n",
    "    if metrix_num == \"1\":\n",
    "        return \"BLOSUM45\"\n",
    "    if metrix_num == \"2\":\n",
    "        return \"BLOSUM62\"  # 62 is not availiable currently\n",
    "    if metrix_num == \"3\":\n",
    "        return \"BLOSUM82\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2. Query_Sequence(genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Query_Seq(genome):\n",
    "    \"\"\"This Function Read Fasta (Genome) file and return as a list Format with gene Position and Sequence Developed by Krish\"\"\"\n",
    "    try:\n",
    "        return [str((seq_record.id+seq_record.seq)) for seq_record in SeqIO.parse(genome, \"fasta\")]\n",
    "        # To understand this Function Bio Python library needs to be studied\n",
    "    except IOError as err:\n",
    "        print(str(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Query_Sequence(genome):\n",
    "    \"\"\"This Function Read Fastaq Files and return as a list Format with gene Position as a index\n",
    "    This Function create a list of Seprate Query Sequence\"\"\"\n",
    "    # This Function is created by using Bio Python we will test later\n",
    "    gene_seq = \"\"\n",
    "    gene_seq_list = []\n",
    "    try:\n",
    "        with open(Species+genome) as gene:\n",
    "            for each_line in gene:\n",
    "                if \">\" in each_line:\n",
    "                    if gene_seq != \"\":\n",
    "                        gene_seq_list.append(gene_seq)\n",
    "                        gene_seq = \"\"\n",
    "                gene_seq = gene_seq+each_line\n",
    "            gene_seq_list.append(gene_seq)\n",
    "            #print(\"Query_Sequence() Run Successfully\")\n",
    "            return gene_seq_list\n",
    "\n",
    "    except IOError as err:\n",
    "        print(\"IOError occurred in Query_Sequence function : \" + str(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Query_Seq(Species+\"AAE\")\n",
    "b= Query_Seq(Species+\"AAE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gi|15605614|ref|NP_212987.1|MAKEKFERTKEHVNVGTIGHVDHGKSTLTSAITCVLAAGLVEGGKAKCFKYEEIDKAPEEKERGITINITHVEYETAKRHYAHVDCPGHADYIKNMITGAAQMDGAILVVSAADGPMPQTREHVLLARQVNVPYIVVFMNKCDMVDDEELLELVELEVRELLSKYEYPGDEVPVIRGSALGALQELEQNSPGKWVESIKELLNAMDEYIPTPQREVDKPFLMPIEDVFSISGRGTVVTGRVERGVLRPGDEVEIVGLREEPLKTVATSIEMFRKVLDEALPGDNIGVLLRGVGKDDVERGQVLAQPGSVKAHKRFRAQVYVLSKEEGGRHTPFFVNYRPQFYFRTADVTGTVVKLPEGVEMVMPGDNVELEVELIAPVALEEGLRFAIREGGRTVGAGVVTKILD',\n",
       " 'gi|15605614|ref|NP_212987.1|MAKEKFERTKEHVNVGTIGHVDHGKSTLTSAITCVLAAGLVEGGKAKCFKYEEIDKAPEEKERGITINITHVEYETAKRHYAHVDCPGHADYIKNMITGAAQMDGAILVVSAADGPMPQTREHVLLARQVNVPYIVVFMNKCDMVDDEELLELVELEVRELLSKYEYPGDEVPVIRGSALGALQELEQNSPGKWVESIKELLNAMDEYIPTPQREVDKPFLMPIEDVFSISGRGTVVTGRVERGVLRPGDEVEIVGLREEPLKTVATSIEMFRKVLDEALPGDNIGVLLRGVGKDDVERGQVLAQPGSVKAHKRFRAQVYVLSKEEGGRHTPFFVNYRPQFYFRTADVTGTVVKLPEGVEMVMPGDNVELEVELIAPVALEEGLRFAIREGGRTVGAGVVTKILD')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1],b[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3.Write_Query(query, parallel_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Write_Query(query, parallel_num):\n",
    "    \"This Function Write Query with file Name query+ parallel_num in same directory and raise IO error if Error rises\"\n",
    "    # print(\"Write_Query(query,parallel_num)\")\n",
    "    try:\n",
    "        with open(\"./query/query_\"+str(parallel_num), \"w\") as write_query:\n",
    "            write_query.write(query)\n",
    "    except IOError as err:\n",
    "        print(\"IOError occurred in Write_Query function : \" + str(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4. Run_Blast( Subject , parallel_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Run_Blast(subject, parallel_num):\n",
    "    \"By this Function it will create a Pipe line to run Blastp in Computer by input Parameter Subject is whole Genome and parallel_number is query file Created by early step\"\n",
    "    #print(\"Runing Run_Blast(subject,parallel_number)\")\n",
    "    # print(\"Passed Parallel Number is \",parallel_num) #parallel_number is the cpu_count\n",
    "    subject = Species+subject\n",
    "    Blastp = \"blastp\"\n",
    "    cmd = [Blastp, \"-query\", \"./query/query_\"+str(parallel_num), \"-subject\", subject,\n",
    "           \"-matrix\", blastp_matrix, \"-outfmt\", \"10 qseqid sseqid score length\"]\n",
    "    # query subject is inside query Folder\n",
    "\n",
    "    #run_blastp =subprocess.Popen(cmd,stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    #run_blastp = subprocess.run(cmd,shell=True ,capture_output = True,text = True)\n",
    "    # output Format 10 qseqid query (e.g. gene sequence id  ,  sseqid subject (e.g. reference genome) genome id)\n",
    "    run_blastp = subprocess.Popen(\n",
    "        cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    #run_blastp_stream = run_blastp.stdout()\n",
    "    run_blastp_stream = run_blastp.communicate()\n",
    "    run_blastp_output_stream = run_blastp_stream[0]\n",
    "    #run_blastp_error_stream = run_blastp_stream[1]\n",
    "    \n",
    "    # Later We can return by this \n",
    "    #return run_blastp.communicate[0]\n",
    "    return run_blastp_output_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Run_Blast1(subject, parallel_num):\n",
    "    \"By this Function it will create a Pipe line to run Blastp in Computer by input Parameter Subject is whole Genome and parallel_number is query file Created by early step\"\n",
    "    #print(\"Runing Run_Blast(subject,parallel_number)\")\n",
    "    # print(\"Passed Parallel Number is \",parallel_num) #parallel_number is the cpu_count\n",
    "    subject = Species+subject\n",
    "    cmd = [\"blastp\", \"-query\", \"./query/query_\"+str(parallel_num), \"-subject\", subject,\n",
    "           \"-matrix\", blastp_matrix, \"-outfmt\", \"10 qseqid sseqid score length\"]\n",
    "    run_blastp = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    \n",
    "    return run_blastp.communicate()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 5. Same_Species_Forward_Best_Hit(blastp_score):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Same_Species_Forward_Best_HIt(blastp_score):\n",
    "    \"\"\"Search the forward best hit among the blastp scores of same species.\n",
    "    Because there are an duplicated genes in a same genome.\n",
    "    blstp_score file is return value of Run_Blast() Function\n",
    "    When the blastp score compare with blastp score of duplicate gene, if score and length are same, blasp score of duplicated gene is added to a second best score.\"\"\"\n",
    "    print(blastp_score)\n",
    "    blastp_score_split_list = []\n",
    "    temp_best_score = ['-1', '-1', '-1']\n",
    "    second_temp_best_score = []\n",
    "    best_score = []\n",
    "    second_best_score = []\n",
    "    blastp_score_split = blastp_score.split(\"\\n\")\n",
    "    # delete of [''] in the last index  ex) ['gi,gi,1,1','gi,gi,2,2','']\n",
    "    del blastp_score_split[-1]\n",
    "    for i in blastp_score_split:\n",
    "        blastp_score_element = i.split(',')\n",
    "        blastp_score_split_list.append(blastp_score_element)\n",
    "    # ex) k is ['gi|15605613|ref|NP_212986.1|', 'gi|15605613|ref|NP_212986.1|', '3702', '699']\n",
    "    for k in blastp_score_split_list:\n",
    "        if k[0] == k[1]: #if the Position (gene) is Same\n",
    "            best_score.append(k)\n",
    "        elif k[0] != k[1]:\n",
    "            if int(k[2]) > int(temp_best_score[2]):  # Compare score\n",
    "                temp_best_score = k\n",
    "            elif int(k[2]) == int(temp_best_score[2]):  # Is Equal\n",
    "                if int(k[3]) > int(temp_best_score[3]):  # compare length\n",
    "                    temp_best_score = k\n",
    "                elif int(k[3]) == int(temp_best_score[3]):\n",
    "                    second_temp_best_score.append(k)\n",
    " #    print (\"############ temp best score ############\", temp_best_score)\n",
    "    second_best_score.append(temp_best_score)\n",
    "    for j in second_temp_best_score:\n",
    "        if j[2] == temp_best_score[2] and j[3] == temp_best_score[3]:\n",
    "            second_best_score.append(j)\n",
    "    for m in second_best_score:\n",
    "        if (best_score[0][2] == m[2] and int(best_score[0][3]) <= int(m[3])) or int(best_score[0][2]) < int(m[2]):\n",
    "             # '104' < '23' is True because of string. So the int function is used.\n",
    "            best_score.append(m)\n",
    "    print(\"best Score is\",best_score)\n",
    "    return best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same_Species_Forward_Best_HIt(a)\n",
    "#a = str(blastp_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 6. Forward_Best_Hit(blastp_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Forward_Best_HIt(blastp_score):\n",
    "    \"\"\"Search the forward best hit among the blastp scores of same species.\"\"\"\n",
    "    #print(\"Rnunning GetForward BestHit\")\n",
    "    blastp_score_split_list = []\n",
    "    temp_best_score = ['-1', '-1', '-1']\n",
    "    second_temp_best_score = []\n",
    "    best_score = []\n",
    "    blastp_score_split = blastp_score.split(\"\\n\")\n",
    "    # delete of ['']   ex) ['gi,gi,1,1','gi,gi,2,2','']\n",
    "    del blastp_score_split[-1]\n",
    "    for i in blastp_score_split:\n",
    "        blastp_score_element = i.split(',')\n",
    "        blastp_score_split_list.append(blastp_score_element)\n",
    "\n",
    "    for k in blastp_score_split_list:\n",
    "        # ex) k is ['gi|15605613|ref|NP_212986.1|', 'gi|15605613|ref|NP_212986.1|', '3702', '699']\n",
    "        # print \">>>>>>>>>>>>>>>Forward_Best_HIt   k\", k\n",
    "        if int(k[2]) > int(temp_best_score[2]):  # Compare the Score of the Blast\n",
    "            temp_best_score = k\n",
    "        elif int(k[2]) == int(temp_best_score[2]):\n",
    "            if int(k[3]) > int(temp_best_score[3]):  # Compare the Lenth of Sequence\n",
    "                temp_best_score = k\n",
    "            elif int(k[3]) == int(temp_best_score[3]):\n",
    "                second_temp_best_score.append(k)\n",
    " #    print \"############ temp best score ############\", temp_best_score\n",
    "    best_score.append(temp_best_score)\n",
    "    for j in second_temp_best_score:\n",
    "        if j[2] == temp_best_score[2] and j[3] == temp_best_score[3]:\n",
    "            best_score.append(j)\n",
    "    return best_score, blastp_score_split_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a,b  = Forward_Best_HIt(blastp_score.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 7. Division_Parallel_Query(queryV,query_division_value, cpu_count , queryV_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Division_Parallel_Query(queryV, query_division_value, cpu_count, queryV_len):\n",
    "    parallel_query = []\n",
    "    parallel_query_start = 0\n",
    "\n",
    "    if queryV_len % cpu_count == 0:  # perfect division\n",
    "        for i in range(cpu_count):\n",
    "            i += 1\n",
    "            if parallel_query_start == 0:\n",
    "                parallel_query.append(\n",
    "                    queryV[int(parallel_query_start):i*int(query_division_value)])\n",
    "                parallel_query_start += 1\n",
    "            else:\n",
    "                parallel_query.append(queryV[int(\n",
    "                    parallel_query_start)*int(query_division_value):i*int(query_division_value)])\n",
    "                parallel_query_start += 1\n",
    "    else:  # imperfect division\n",
    "        for i in range(cpu_count):\n",
    "            i += 1\n",
    "            if parallel_query_start == 0:\n",
    "                parallel_query.append(\n",
    "                    queryV[int(parallel_query_start):i*int(query_division_value)])\n",
    "                parallel_query_start += 1\n",
    "            elif i < cpu_count:\n",
    "                parallel_query.append(queryV[int(\n",
    "                    parallel_query_start)*int(query_division_value):i*int(query_division_value)])\n",
    "                parallel_query_start += 1\n",
    "            elif i == cpu_count:\n",
    "                parallel_query.append(\n",
    "                    queryV[int(parallel_query_start)*int(query_division_value):])\n",
    "                parallel_query_start += 1\n",
    "\n",
    "    return parallel_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 8. Run_Parallel_Query(species_of_query, species_of_subject, queryV, parallel_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'blastp_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-ffcd6f571fb0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#type(blastp_score.decode(\"utf-8\"))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m \u001b[1;33m(\u001b[0m \u001b[1;34m\"test.txt\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblastp_score\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'blastp_score' is not defined"
     ]
    }
   ],
   "source": [
    "#type(blastp_score.decode(\"utf-8\"))\n",
    "with open ( \"test.txt\",\"w\") as t:\n",
    "    t.write(blastp_score.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'queryV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-4cace44973af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mspecies_of_query\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mspecies_of_subject\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mqueryV\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mWrite_Query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparallel_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mblastp_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRun_Blast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselected_species_dic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mspecies_of_subject\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'queryV' is not defined"
     ]
    }
   ],
   "source": [
    "parallel_num = 1\n",
    "species_of_query = 1\n",
    "species_of_subject = 1\n",
    "for j in queryV:\n",
    "    Write_Query(j,parallel_num)\n",
    "    blastp_score = Run_Blast(selected_species_dic[species_of_subject],1)\n",
    "    if blastp_score != \" \":\n",
    "        best_score,blastp_score_split_list = Forward_Best_HIt(blastp_score.decode(\"utf-8\"))\n",
    "        if species_of_query == species_of_subject:\n",
    "            same_species_forward_best_score = Same_Species_Forward_Best_HIt(blastp_score.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward_Best_Hit(blastp_score)\n",
    "blastp_score_split_list = []\n",
    "temp_best_score = [\"-1\",'-1',\"-1\"]\n",
    "second_temp_best_score = []\n",
    "best_score = []\n",
    "second_best_score = []\n",
    "blastp_score_split = blastp_score.decode().split(\"\\n\")\n",
    "\n",
    "del blastp_score_split[-1]\n",
    "for i in blastp_score_split:\n",
    "    blastp_score_element = i.split(\",\")\n",
    "    #display(blastp_score_element)\n",
    "    blastp_score_split_list.append(blastp_score_element)\n",
    "# k is ['gi|15605613|ref|NP_212986.1|', 'gi|15605613|ref|NP_212986.1|', '3702', '699']\n",
    "for k in blastp_score_split_list:\n",
    "    if k[0] == k[1]:\n",
    "        best_score.append(k)\n",
    "    elif k[0] != k[1]:\n",
    "        if int(k[2])> int(temp_best_score[2]):\n",
    "            temp_best_score = k\n",
    "        elif int(k[2])==int(temp_best_score[2]):\n",
    "            if int(k[3])>int(temp_best_score[3]):\n",
    "                temp_best_score = k\n",
    "            elif int(k[3]) == int(temp_best_score[3]):\n",
    "                second_temp_best_score.append(k)\n",
    "second_temp_best_score.append(temp_best_score)\n",
    "for j in second_temp_best_score:\n",
    "    if j[2] == temp_best_score[2] and j[3] == temp_best_score[3]:\n",
    "        second_best_score.append(j)\n",
    "#for m in second_best_score:\n",
    "#    if (best_score[0][2]==m[2] and int(best_score[0][3])<=int(m[3])) or int(best_score[0][2])<int(m[2]):\n",
    "#        best_score.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_best_score\n",
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(temp_best_score)\n",
    "#display(best_score[0])\n",
    "#display(second_temp_best_score)\n",
    "#blastp_score\n",
    "#blastp_matrix\n",
    "#Run_Parallel_Query(1,1,queryV,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Run_Parallel_Query(species_of_query, species_of_subject, queryV, parallel_num):\n",
    "    \"\"\" Run_Parallel_Query(i ,k , queryV , cpu_count) i and k are user selected number in a list Format\n",
    "    Run the following functions. Write_Query, Run_Blast, Same_Species_Forward_Best_HIt, Forward_Best_HIt\n",
    "    Save the files which are oneway_threshold_best_hit, second_oneway_threshold_best_hit, \n",
    "    blastp_score_split_list and raw_blastp_score (optional) by each species. \n",
    "    parallel_num is the Number of CPU selected by the user if CPu 1 selected then 1 \"\"\"\n",
    "\n",
    "    #print(\"Run_Parallel_Query Running\")\n",
    "    global selected_number, selected_species_dic\n",
    "\n",
    "    # bar = Bar('Processing '+str(parallel_num), max = len(queryV)) #progressing bar setting , Creating a Object\n",
    "    # bar is not Supported in Python 3    We use alive_bar instead\n",
    "    with alive_bar(len(queryV)) as bar:  # declare your set of items for loop\n",
    "        for j in queryV:\n",
    "            i = 10\n",
    "            # bar.next() #progressing bar not supported\n",
    "            bar()  # Call after Consuming One Item\n",
    "            Write_Query(j, parallel_num)  # if 1 Added Here Add also to Run\n",
    "            Write_Query(j, i)\n",
    "            i += 1  # !Only For checking Delete later\n",
    "        # This Function Only Write a file with j name and parallel_num i.e CPU Count\n",
    "            blastp_score = Run_Blast(\n",
    "                selected_species_dic[species_of_subject], parallel_num)\n",
    "        # Return Byte File type\n",
    "            if blastp_score != '':  # Check whether blastp_score has the value\n",
    "                best_score, blastp_score_split_list = Forward_Best_HIt(\n",
    "                    blastp_score.decode(\"utf-8\"))  # .decode() Convert in to str format\n",
    "                # ex) AAE == AAE. It will save best_score without reversing Run_Blast.\n",
    "                if species_of_query == species_of_subject:\n",
    "                    same_species_forward_best_score = Same_Species_Forward_Best_HIt(\n",
    "                        blastp_score.decode())\n",
    "                    for best_score_element in same_species_forward_best_score:\n",
    "                        # ex) [A1 of AAE, A1 of AAE, 30]\n",
    "                        if best_score_element[0] == best_score_element[1]:\n",
    "\n",
    "                            with open(Score_file+selected_species_dic[species_of_query] + \"_\" +\n",
    "                                      selected_species_dic[species_of_subject]\n",
    "                                      + \"_oneway_threshold_best_hit_Score\"\n",
    "                                      + str(threshold_score), \"a\") as oneway_threshold_best_hit:\n",
    "                                save_best_score = selected_species_dic[species_of_query]+\"_\"+best_score_element[0].split(\"\\s\")[0]\\\n",
    "                                    + \" \"+selected_species_dic[species_of_subject]+\"_\"+best_score_element[1].split(\n",
    "                                        \"\\s\")[0]+\" \"+best_score_element[2]+\"\\n\"\n",
    "                                # best_score_element[0].split(\"|\") ==> ['gi', '15642790', 'ref', 'NP_227831.1', '']\n",
    "                                oneway_threshold_best_hit.write(\n",
    "                                    save_best_score)\n",
    "                        else:  # ex) [A1 of AAE, A2 of AAE, 30]\n",
    "                            with open(Score_file+selected_species_dic[species_of_query]+\"_\"\n",
    "                                      + selected_species_dic[species_of_subject]\n",
    "                                      + \"_second_oneway_threshold_best_hit_Score\"\n",
    "                                      + str(threshold_score), \"a\") as second_oneway_threshold_best_hit:\n",
    "                                second_save_best_score = selected_species_dic[species_of_query]\\\n",
    "                                    + \"_\"+best_score_element[0].split(\"\\s\")[0]\\\n",
    "                                    + \" \"+selected_species_dic[species_of_subject]+\"_\"\\\n",
    "                                    + best_score_element[1].split(\"\\s\")[0]+\" \"+best_score_element[2]+\"\\n\"\n",
    "                                second_oneway_threshold_best_hit.write(\n",
    "                                    second_save_best_score)\n",
    "                else:  # If species_of_query not equal with species_of_subject, run reversing Run_Blast\n",
    "                    for best_score_element in best_score:\n",
    "                        if not '-1' in best_score_element:\n",
    "                            with open(Score_file+selected_species_dic[species_of_query]\n",
    "                                      + \"_\" +\n",
    "                                      selected_species_dic[species_of_subject] +\n",
    "                                      \"_\"+\"best_score_S\"\n",
    "                                      + str(threshold_score)+\"_\"+str(parallel_num), \"a\") as save_best_hit:\n",
    "                                best_score_save = selected_species_dic[species_of_query]+\"_\"\\\n",
    "                                    + best_score_element[0].split(\"\\s\")[0]+\" \"+selected_species_dic[species_of_subject]\\\n",
    "                                    + \"_\"+best_score_element[1].split(\n",
    "                                        \"\\s\")[0]+\" \"+best_score_element[2]+\" \"+best_score_element[3]+\"\\n\"\n",
    "                                save_best_hit.write(best_score_save)\n",
    "\n",
    "                    for blastp_score_split_list_element in blastp_score_split_list:\n",
    "                        with open(Score_file+selected_species_dic[species_of_query]+\"_\"\n",
    "                                  + selected_species_dic[species_of_subject]+\"_\"+\"blastp_score_split_list_S\"\n",
    "                                  + str(threshold_score)+\"_\"+str(parallel_num), \"a\") as save_blastp_score_split_list:\n",
    "                            blastp_score_split_list_save = selected_species_dic[species_of_query]+\"_\"\\\n",
    "                                + blastp_score_split_list_element[0].split(\"\\s\")[0]\\\n",
    "                                + \" \"+selected_species_dic[species_of_subject]+\"_\"+blastp_score_split_list_element[1].split(\"\\s\")[0]\\\n",
    "                                + \" \" + \\\n",
    "                                blastp_score_split_list_element[2]+\" \" \\\n",
    "                                + blastp_score_split_list_element[3]+\"\\n\"\n",
    "                            save_blastp_score_split_list.write(\n",
    "                                blastp_score_split_list_save)\n",
    "\n",
    "            if save_raw_blastp_score:\n",
    "                with open(Score_file+selected_species_dic[species_of_query]\n",
    "                          + \"_\"+selected_species_dic[species_of_subject]+\"_S\"\n",
    "                          + str(threshold_score)+\"_\"+str(parallel_num), \"a\") as save_blastp:\n",
    "                    save_blastp.write(blastp_score) #decode()\n",
    "    # bar.finish() # progressing bar finish\n",
    "    return  # None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 9.Oneway_Threshold_Best_Hit(mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Oneway_Threshold_Best_Hit(mode):\n",
    "    \"\"\" This Function accept the mode and Run program and return backward_best_hit_work_list  \"\"\"\n",
    "    #print(\"OneWay_Threshold_Best_Hit running\")\n",
    "    global user_selected_number, cpu_count\n",
    "    process_list = []\n",
    "    backward_best_hit_work_list = []\n",
    "    if \"1\" in mode:\n",
    "        print(\"Blastp Mode is Selected\")\n",
    "        # We have 3 Mode 1 is for blastp\n",
    "        # Mode 2 is for BLASTP using precalcualted data and Mode 3 is for Clustering\n",
    "        for i in user_selected_number:  # Select species to write query\n",
    "            queryV = Query_Sequence(selected_species_dic[i])\n",
    "            # queryV is a list Format  with a position gene id , Seq\n",
    "            # User Selected  [1, 3, 5] is list of User input\n",
    "            for k in user_selected_number:\n",
    "                if k < i:  # gene ====> query 1->1 1->2 1->3 2->2 2->3  Forward checking will skip the same or less\n",
    "                    continue\n",
    "                else:\n",
    "                    print(\"Doing the blastp & forward best hit searches between %s genome and %s genome\"\n",
    "                          % (selected_species_dic[i], selected_species_dic[k]))\n",
    "                    # this will Create a loop though 2 times\n",
    "\n",
    "                    # length of Genome gene ID in Sequence File\n",
    "                    queryV_len = len(queryV)\n",
    "                    if cpu_count == 1:\n",
    "                        print(\"cput_count =\", cpu_count)\n",
    "                        blastp_time_start = time.time()\n",
    "                        Run_Parallel_Query(i, k, queryV, cpu_count)\n",
    "                        blastp_time_end = time.time()\n",
    "                        print(\"The blastp & forward best hit searches took %.2f minutes\" % (\n",
    "                            (blastp_time_end-blastp_time_start)/60))\n",
    "                    else:\n",
    "                        # If the number of queryV_len is less than cpu_count, Remark will select the number of queryV_len.\n",
    "                        if queryV_len < cpu_count:\n",
    "                            blastp_time_start = time.time()\n",
    "                            # 1 is query_division_value. Because queryV_len / queryV_len(=cpu_count) is 1.\n",
    "                            parallel_query = Division_Parallel_Query(\n",
    "                                queryV, 1, queryV_len, queryV_len)\n",
    "                            for m in range(queryV_len):\n",
    "                                process = multiprocessing.Process(\n",
    "                                    target=Run_Parallel_Query, args=(i, k, parallel_query[m], m+1))\n",
    "                                # args( i => species of query , k => species of subject, m+1 => cpu_count ex) 1, 2 ...)\n",
    "                                process_list.append(process)\n",
    "                                process.start()\n",
    "                            for n in process_list:\n",
    "                                n.join()\n",
    "                            blastp_time_end = time.time()\n",
    "                            print(\"The blastp & forward best hit searches took %.2f minutes\" % (\n",
    "                                (blastp_time_end-blastp_time_start)/60))\n",
    "                        else:\n",
    "                            blastp_time_start = time.time()\n",
    "                            query_division_value = queryV_len / cpu_count\n",
    "                            parallel_query = Division_Parallel_Query(\n",
    "                                queryV, query_division_value, cpu_count, queryV_len)\n",
    "                            for m in range(cpu_count):\n",
    "                                process = multiprocessing.Process(\n",
    "                                    target=Run_Parallel_Query, args=(i, k, parallel_query[m], m+1))\n",
    "                                # args( i => species of query , k => species of subject, m+1 => cpu_count ex) 1, 2 ...)\n",
    "                                process_list.append(process)\n",
    "                                process.start()\n",
    "                            for n in process_list:\n",
    "                                n.join()\n",
    "                            blastp_time_end = time.time()\n",
    "                            print(\"The blastp & forward best hit searches took %.2f minutes\" % (\n",
    "                                (blastp_time_end-blastp_time_start)/60))\n",
    "                if not i == k:\n",
    "                    backward_best_hit_work_list.append((i, k, queryV_len))\n",
    "                    print(\"Backward\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blastp Mode is Selected\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'user_selected_number' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-f198dfdd601e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbackward_best_hit_work_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Blastp Mode is Selected\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0muser_selected_number\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mqueryV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mQuery_Sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselected_species_dic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0muser_selected_number\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'user_selected_number' is not defined"
     ]
    }
   ],
   "source": [
    "mode = \"1\"\n",
    "process_list = []\n",
    "backward_best_hit_work_list = []\n",
    "print(\"Blastp Mode is Selected\")\n",
    "for i in user_selected_number:\n",
    "    queryV = Query_Sequence(selected_species_dic[i])\n",
    "    for k in user_selected_number:\n",
    "        if k<i:\n",
    "            continue\n",
    "        else:\n",
    "            print(\"Doing the blastp and Forward best hit searche\")\n",
    "            queryV_len = len(queryV)\n",
    "            print(queryV)\n",
    "            \n",
    "            if cpu_count ==1:\n",
    "                #Run_Parallel_Query(i,k,queryV,cpu_count)\n",
    "                display(i,k)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-23-876d93478f72>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-23-876d93478f72>\"\u001b[1;36m, line \u001b[1;32m10\u001b[0m\n\u001b[1;33m    with open(Score_file+selected_species_dic[species_of_subject]+)\u001b[0m\n\u001b[1;37m                                                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Back Ward _best _hit\n",
    "species_of_query = 1\n",
    "species_of_subject = 3\n",
    "queryV_len = len(queryV)\n",
    "foward_best_hit_score_list = []\n",
    "blastp_score_split_list = []\n",
    "if queryV_len< cpu_count:\n",
    "    for parallel_num in range(queryV_len):\n",
    "        parallel_num += 1\n",
    "        with open(Score_file+selected_species_dic[species_of_subject]+)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 10. Backward_Best_Hit(args):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Backward_Best_Hit(args):\n",
    "    print(\"Running Backward_Best_Hit\")\n",
    "    species_of_query, species_of_subject, queryV_len = args\n",
    "    start_time_BBH = time.time()\n",
    "    forward_best_hit_score_list = []\n",
    "    blastp_score_split_list = []\n",
    "    print(\"Run the backward best hit between %s genome %s genome\" % (\n",
    "        selected_species_dic[species_of_query], selected_species_dic[species_of_subject]))\n",
    "    # If the number of queryV_len is less than cpu_count, the cpu_count is changed to queryV_len.\n",
    "    if queryV_len < cpu_count:\n",
    "        for parallel_num in range(queryV_len):\n",
    "            parallel_num += 1\n",
    "            with open(Score_file+selected_species_dic[species_of_query]+\"_\"\n",
    "                      + selected_species_dic[species_of_subject] + \"_\"+\"best_score_S\"\n",
    "                      + str(threshold_score)+\"_\"+str(parallel_num), \"r\") as best_hit_score:\n",
    "                for each_line in best_hit_score:\n",
    "                    split_each_line = each_line.split(\" \")\n",
    "                    split_each_line[2] = int(split_each_line[2])\n",
    "                    split_each_line[3] = int(split_each_line[3])\n",
    "        #            print split_each_line\n",
    "                    forward_best_hit_score_list.append(split_each_line)\n",
    "            with open(Score_file+selected_species_dic[species_of_query]+\"_\"\n",
    "                      + selected_species_dic[species_of_subject] +\n",
    "                      \"_\"+\"blastp_score_split_list_S\"\n",
    "                      + str(threshold_score)+\"_\"+str(parallel_num), 'r') as blastp_score:\n",
    "                for each_line in blastp_score:\n",
    "                    split_each_line = each_line.split(\" \")\n",
    "                    split_each_line[2] = int(split_each_line[2])\n",
    "                    split_each_line[3] = int(split_each_line[3])\n",
    "        #            print split_each_line\n",
    "                    blastp_score_split_list.append(split_each_line)\n",
    "    else:\n",
    "        for parallel_num in range(cpu_count):\n",
    "            parallel_num += 1\n",
    "            with open(Score_file+selected_species_dic[species_of_query]+\"_\"\n",
    "                      + selected_species_dic[species_of_subject]+\"_\"+\"best_score_S\"\n",
    "                      + str(threshold_score)+\"_\"+str(parallel_num), \"r\") as best_hit_score:\n",
    "                for each_line in best_hit_score:\n",
    "                    split_each_line = each_line.split(\" \")\n",
    "\n",
    "                    split_each_line[3] = int(split_each_line[3])\n",
    "        #            print split_each_line\n",
    "                    forward_best_hit_score_list.append(split_each_line)\n",
    "            with open(Score_file+selected_species_dic[species_of_query] + \"_\"\n",
    "                      + selected_species_dic[species_of_subject]\n",
    "                      + \"_\"+\"blastp_score_split_list_S\"\n",
    "                      + str(threshold_score)+\"_\"+str(parallel_num), 'r') as blastp_score:\n",
    "                for each_line in blastp_score:\n",
    "                    split_each_line = each_line.split(\" \")\n",
    "                    split_each_line[2] = int(split_each_line[2])\n",
    "                    split_each_line[3] = int(split_each_line[3])\n",
    "        #            print split_each_line\n",
    "                    blastp_score_split_list.append(split_each_line)\n",
    "\n",
    "    #bar = Bar(\"Searching : \"+selected_species_dic[species_of_query]+\"-\"+selected_species_dic[species_of_subject], max = len(forward_best_hit_score_list))\n",
    "\n",
    "    for forward_best_hit_score_element in forward_best_hit_score_list:\n",
    "        matching_list = []\n",
    "        backward_best_score = ['-1', '-1', '-1']\n",
    "        # bar.next()\n",
    "        for element in blastp_score_split_list:\n",
    "            if element[1] == forward_best_hit_score_element[1]:\n",
    "                matching_list.append(element)\n",
    "\n",
    "        for element in matching_list:\n",
    "            if int(element[2]) > int(backward_best_score[2]):\n",
    "                backward_best_score = element\n",
    "    #        with open('./'+selected_species_dic[species_of_query]\\\n",
    "    # +\"_\"+selected_species_dic[species_of_subject]+'_subtraction'+\"_\"+str(threshold_score), 'a') as subtraction :\n",
    "    #            save_data = int(backward_best_score[2]) - int(forward_best_hit_score_element[2])\n",
    "    #            subtraction.write(str(save_data)+\"\\n\")\n",
    "\n",
    "        if int(backward_best_score[2]) - int(forward_best_hit_score_element[2]) <= threshold_score:\n",
    "            with open(Score_file+selected_species_dic[species_of_query]\n",
    "                      + \"_\"+selected_species_dic[species_of_subject]\n",
    "                      + \"_oneway_threshold_best_hit_Score\"+str(threshold_score), \"a\")\\\n",
    "                    as other_oneway_threshold_best_hit:\n",
    "                save_data = forward_best_hit_score_element[0]\\\n",
    "                    + \" \"+forward_best_hit_score_element[1]\\\n",
    "                    + \" \" + str(int(forward_best_hit_score_element[2]))+\"\\n\"\n",
    "                other_oneway_threshold_best_hit.write(save_data)\n",
    "\n",
    "    # bar.finish()\n",
    "    finish_time_BBH = time.time()\n",
    "    RBH_time = float((finish_time_BBH - start_time_BBH)/60)\n",
    "    print(\"BackwardBestHit of %s-%s took %.2f minutes\" %\n",
    "          (selected_species_dic[species_of_query], selected_species_dic[species_of_subject], RBH_time))\n",
    "    return RBH_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 11. Search_Equal_BBH_Data(target_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Search_Equal_BBH_Data(target_A):\n",
    "    \"\"\"Search the equal backward best hit data. ex) AAE_AAE_backward_best_hit \"\"\"\n",
    "    # print(\"Search_Equal_BBH_Data\")\n",
    "    put_data = equal_BBH_data_dic[target_A]\n",
    "    if put_data[1] == 0:\n",
    "        pass\n",
    "    else:\n",
    "        copy_put_data = copy.copy(put_data)\n",
    "        copy_put_data.insert(0, target_A)\n",
    "        results.put(copy_put_data)\n",
    "        equal_BBH_data_dic[target_A][1] = 0\n",
    "    #        print \"---put zero in Search_Equal_BBH_Data----- \", equal_BBH_data_dic[target_A]\n",
    "        for i in second_equal_BBH_data:\n",
    "            if i[2] == 0:\n",
    "                pass\n",
    "            else:\n",
    "                if i[0] == target_A or i[1] == target_A:\n",
    "                    copy_second_put_data = copy.copy(i)\n",
    "                    # Don't put results as queue. Because the tasks will put copy_second_put_data to results as queue.\n",
    "                    tasks.put(copy_second_put_data)\n",
    "                    i[2] = 0\n",
    "    #                    print \"---put zero in second_equal_BBH_data---\", i\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  12. Search_Unequal_BBH_Data(target_B):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Search_Unequal_BBH_Data(target_B):\n",
    "    \"\"\"Search the unequal backward best hit data. ex) AAE_CAC_backward_best_hit\"\"\"\n",
    "    print(\"Search_Unequal_BBH_Data\")\n",
    "    for i in unequal_BBH_data:\n",
    "        if i[2] == 0:\n",
    "            pass\n",
    "        else:\n",
    "            if target_B[0] == i[0] or target_B[0] == i[1] or target_B[1] == i[0] or target_B[1] == i[1]:\n",
    "                copy_i = copy.copy(i)\n",
    "                tasks.put(copy_i)\n",
    "                unequal_BBH_data[unequal_BBH_data.index(i)][2] = 0\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 13.Matching_BBH(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Matching_BBH(target):\n",
    "    \"\"\" Match the backward best hit \"\"\"\n",
    "    #print(\"running Matching_BBH\")\n",
    "    if target[2] == 0:\n",
    "        return\n",
    "\n",
    "    else:\n",
    "        copy_target = copy.copy(target)\n",
    "        Search_Equal_BBH_Data(copy_target[0])\n",
    "        Search_Equal_BBH_Data(copy_target[1])\n",
    "        results.put(copy_target)\n",
    "        unequal_BBH_data[unequal_BBH_data.index(target)][2] = 0\n",
    "\n",
    "    for j in unequal_BBH_data:\n",
    "        if j[2] == 0:\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            if copy_target[0] == j[0] or copy_target[0] == j[1] or copy_target[1] == j[0] or copy_target[1] == j[1]:\n",
    "                copy_j = copy.copy(j)\n",
    "                # print \"targ_get , j = %s %s\" % (copy_target, j)\n",
    "                unequal_BBH_data[unequal_BBH_data.index(j)][2] = 0\n",
    "                tasks.put(copy_j)\n",
    "\n",
    "    while not tasks.empty():\n",
    "        get_task = tasks.get()\n",
    "        Search_Equal_BBH_Data(get_task[0])\n",
    "        Search_Equal_BBH_Data(get_task[1])\n",
    "        results.put(get_task)\n",
    "        Search_Unequal_BBH_Data(get_task)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 14.Generating_Matrix_Clustering_Ortholog(element_set,bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generating_Matrix_Clustering_Ortholog(element_set):\n",
    "    # Generating_Matrix_Clustering_Ortholog(element_set, bar): # this is Old Method\n",
    "    \"\"\" Generate the matrix of clustering ortholog. \"\"\"\n",
    "    print(\"Generating_Matrix_Clustering_Ortholog\")\n",
    "    row_data = []\n",
    "    col_data = []\n",
    "    temp_results = queue.Queue()\n",
    "    # bar.next()\n",
    "    for element in element_set:\n",
    "        # if element[0] exist, returning the index in the row_data.\n",
    "        if row_data.count(element[0]) > 0:\n",
    "            # element[0] is data of row. ['gi|15606057|ref|NP_213434.1|', 'gi|15606057|ref|NP_213434.1|', '3823\\n']\n",
    "            row = row_data.index(element[0])\n",
    "\n",
    "        else:\n",
    "            row = len(row_data)\n",
    "            row_data.append(element[0])\n",
    "            # if element[0] doesn't exist, appending the element[0] to the col_data.\n",
    "            if col_data.count(element[0]) < 1:\n",
    "                col_data.append(element[0])\n",
    "\n",
    "        if col_data.count(element[1]) > 0:\n",
    "            col = col_data.index(element[1])  # element[1] is data of col.\n",
    "\n",
    "        else:\n",
    "            col = len(col_data)\n",
    "            col_data.append(element[1])\n",
    "            if row_data.count(element[1]) < 1:\n",
    "                col_data.append(element[1])\n",
    "\n",
    "        temp_results.put([row, col, element[2]])\n",
    "    # create a new matrix of given shape(the size_resuls) and type, filled with zeros.\n",
    "    score_matrix = numpy.matlib.zeros(\n",
    "        (len(row_data), len(col_data)), dtype=np.float)\n",
    "    # np.zeros() can be used, will test later,\n",
    "    while not temp_results.empty():\n",
    "        get_temp_results = temp_results.get()\n",
    "        row = get_temp_results[0]\n",
    "        col = get_temp_results[1]\n",
    "        score_matrix[row, col] = get_temp_results[2]\n",
    "        score_matrix[col, row] = get_temp_results[2]\n",
    "    # If the elements of row and col is less than 2, it is excluded.\n",
    "    if len(row_data)*len(col_data) > 4:\n",
    "        # The big size of matrix(bigger than 1000 X 1000) will be computed by Parallel_Matrix_Multiplication function.\n",
    "        if len(row_data) > 1000 and cpu_count > 1:\n",
    "            score_matrix = Parallel_MCL(score_matrix)\n",
    "        else:\n",
    "            score_matrix = MCL(score_matrix)\n",
    "        Clustering(row_data, col_data, score_matrix)\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 15.Parallel_MCL(score_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Parallel_MCL(score_matrix):\n",
    "    # print(\"Parallel_MCL\")\n",
    "    count = 0\n",
    "    infinitesimal_value = 10**-10\n",
    "    idempotent_matrix = numpy.matlib.ones((2, 2))\n",
    "\n",
    "    while idempotent_matrix.sum() > infinitesimal_value:  # > infinitesimal_value\n",
    "        MCL_time_start = time.time()\n",
    "        pool = multiprocessing.Pool(cpu_count)  # create a expansion_matrix\n",
    "        multiplication_results = pool.map(Parallel_Matrix_Multiplication,\n",
    "                                          zip(score_matrix, repeat(score_matrix)))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "        # create a inflation_matrix(part 1)\n",
    "        pool = multiprocessing.Pool(cpu_count)\n",
    "        power_results = pool.map(\n",
    "            Parallel_Matrix_Power, multiplication_results)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "        sum_matrix = 0\n",
    "        for i in power_results:\n",
    "            sum_matrix = i + sum_matrix\n",
    "\n",
    "        # create a inflation_matrix(part 2)\n",
    "        pool = multiprocessing.Pool(cpu_count)\n",
    "        divide_results = pool.map(Parallel_Matrix_Division,\n",
    "                                  zip(power_results, repeat(sum_matrix)))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "        # Make a Combined matrix for results of Parallel_Matrix_Multiplication function.\n",
    "        for i in range(len(divide_results)):\n",
    "            if i == 0:\n",
    "                score_matrix = divide_results[i]\n",
    "            else:\n",
    "                score_matrix = np.concatenate(\n",
    "                    (score_matrix, divide_results[i]), axis=0)\n",
    "\n",
    "        sum_results = 0\n",
    "        for i in multiplication_results:\n",
    "            sum_results += i\n",
    "        # identify whether inflation_matrix is idempotent matrix or not.\n",
    "        idempotent_matrix = abs(np.sum(score_matrix) - sum_results)\n",
    "\n",
    "        count += 1\n",
    "        if count > infinite_loop:  # It will prevent the infinite loop of MCL algorithm.\n",
    "            break\n",
    "        MCL_time_finish = time.time()\n",
    "        if verbose:\n",
    "            print(\" MCL time : %f, count : %d, matrix size : %d * %d\"\n",
    "                  % ((MCL_time_finish - MCL_time_start)/60, count, score_matrix[0].size, score_matrix[0].size))\n",
    "    return score_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 16. MCL(score_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCL(score_matrix):\n",
    "    count = 0\n",
    "    infinitesimal_value = 10**-10\n",
    "    idempotent_matrix = numpy.matlib.ones((2, 2))\n",
    "    #idempotent_matrix = np.ones((2,2))\n",
    "    while idempotent_matrix.sum() > infinitesimal_value:  # > infinitesimal_value\n",
    "        MCL_time_start = time.time()\n",
    "        expansion_matrix = score_matrix ** 2\n",
    "        score_matrix = np.power(expansion_matrix, inflation_factor)\n",
    "        score_matrix_sum = score_matrix.sum(axis=0)\n",
    "        # create a inflation_matrix\n",
    "        score_matrix = np.divide(score_matrix, score_matrix_sum)\n",
    "        # identify whether inflation_matrix is idempotent matrix or not.\n",
    "        idempotent_matrix = abs(score_matrix - expansion_matrix)\n",
    "        count += 1\n",
    "        if count > infinite_loop:  # It will prevent the infinite loop of MCL algorithm.\n",
    "            break\n",
    "        MCL_time_finish = time.time()\n",
    "        if verbose:\n",
    "            print(\" MCL time : %f, count : %d, matrix size : %d * %d\" \\\n",
    "                  %((MCL_time_finish - MCL_time_start)/60, count, score_matrix[0].size, score_matrix[0].size))\n",
    "    return score_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 17. Clustering(row_data, col_data, score_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Clustering(row_data, col_data, score_matrix):\n",
    "    global cluster_count\n",
    "    global ortholog_count\n",
    "    ortholog_temp_list = []\n",
    "    for i in range(len(row_data)):\n",
    "        ortholog_list = []\n",
    "        ortholog_sum = 0\n",
    "        ortholog = queue.Queue()  # It is Queue which is put the ortholog.\n",
    "        # It is Queue which is put the ortholog having changed gene ID\n",
    "        gene_id_queue = queue.Queue()\n",
    "        for j in range(len(col_data)):\n",
    "            if 0.1 <= score_matrix[i, j]:\n",
    "                ortholog.put(col_data[j])\n",
    "                ortholog_list.append(col_data[j])\n",
    "\n",
    "        # If the ortholog queue  has the element of ortholog more than 2, it will be printed.\n",
    "        if ortholog.qsize() >= 3:\n",
    "            for element in ortholog_list:\n",
    "                try:\n",
    "                    ortholog_sum += ortholog_temp_list.index(element)+1\n",
    "\n",
    "                except ValueError:\n",
    "                    with open(Cluster_out+\"_geneID_S\"+str(threshold_score) +\n",
    "                              \"_\"+str(inflation_factor), \"a\") as ortholog_list_save:\n",
    "                        ortholog_print = \"cluster \"+str(cluster_count)+\" :\"\n",
    "                        ortholog_list_save.write(ortholog_print)\n",
    "\n",
    "                        while not ortholog.empty():\n",
    "                            get_ortholog = ortholog.get()\n",
    "                            ortholog_list_save.write(\"\\t\"+get_ortholog)\n",
    "\n",
    "                            try:\n",
    "                                # get_ortholog --> ECO_170082288,  get_ortholog.split('_') --> ['ECO', '170082288']\n",
    "                                get_ortholog_split = get_ortholog.split('_')\n",
    "                                gene_id_queue.put(\n",
    "                                    get_ortholog_split[0]+\"_\"+gene_id_dic[get_ortholog_split[1]])\n",
    "                            except KeyError:\n",
    "                                # If the gene_id_dic don't have get_ortholog, it will print the original ID(get_ortholog).\n",
    "                                gene_id_queue.put(get_ortholog)\n",
    "                        ortholog_list_save.write(\"\\n\")\n",
    "                    with open(Cluster_out+\"_KO_ID_S\"\n",
    "                              + str(threshold_score)\n",
    "                              + \"_\"+str(inflation_factor), \"a\")\\\n",
    "                            as ortholog_list_geneID_save:\n",
    "                        ortholog_list_geneID_print = \"cluster \" + \\\n",
    "                            str(cluster_count)+\" :\"\n",
    "                        ortholog_list_geneID_save.write(\n",
    "                            ortholog_list_geneID_print)\n",
    "                        while not gene_id_queue.empty():\n",
    "                            ortholog_list_geneID_save.write(\n",
    "                                \"\\t\"+gene_id_queue.get())\n",
    "                            ortholog_count += 1\n",
    "                        cluster_count += 1\n",
    "                        ortholog_list_geneID_save.write(\"\\n\")\n",
    "                    break\n",
    "            ortholog_temp_list = operator.concat(\n",
    "                ortholog_temp_list, ortholog_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 18.Parallel_Matrix_Multiplication(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Parallel_Matrix_Multiplication(data):\n",
    "    \"Doing Parallel_Matrix_Multiplication Using Numpy\"\n",
    "    matrix_element, matrix = data\n",
    "    result = matrix_element * matrix\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 19.Parallel_Matrix_Power(matrix_element):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Parallel_Matrix_Power(matrix_element):\n",
    "    \"This Function Compute Parallel_Matrix Power by using Numpy np.power() Function\"\n",
    "    power_matrix_element = np.power(matrix_element, inflation_factor)\n",
    "    return power_matrix_element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 20.Parallel_Matrix_Division(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Parallel_Matrix_Division(data):\n",
    "    \"This Function Will Perform Matrix Division by Using Numpy library\"\n",
    "    matrix_element, sum_data = data\n",
    "    return np.divide(matrix_element, sum_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 21. Read_Species(pr = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Read_Species(pr=1):  # default 1 which will always shows the name of Species\n",
    "    \"\"\" If pr is 1, it will print \"Species_List\"  Other wise only return the Value in dic Format \"\"\"\n",
    "    read_species = os.listdir(Species)\n",
    "    selected_species_dic = {}  # list\n",
    "    backward_selected_species_dic = {}  # list\n",
    "    for i, species in enumerate(sorted(read_species), start=1):\n",
    "        selected_species_dic[i] = species\n",
    "        backward_selected_species_dic[species] = i\n",
    "        if pr == 1:\n",
    "            print(str(i)+\".\", species)\n",
    "        number = i\n",
    "    return selected_species_dic, backward_selected_species_dic, number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read_Species(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 22. Del_File(path,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Del_File(path, file):\n",
    "    try:\n",
    "        os.remove(path+file)\n",
    "        print(\"File Successfully Removed\")\n",
    "    except:\n",
    "        print(\"Check the File or Path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Del_File(\"./query/\",\"query_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 23.Check_File(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Check_File(file):\n",
    "    \"Check the file weather exist or not  This will run after Mode 3 is selected\"\n",
    "    print(\"Check_File(%s)is running\"%file)\n",
    "    # Declare all variable as a globally Added\n",
    "    global Cluster_out, threshold_score, infinite_loop\n",
    "    file_list = glob.glob(file+'*') #list all related files\n",
    "    #file_list = os.listdir(file)\n",
    "    if (Cluster_out+\"_geneID_S\"+str(threshold_score)\n",
    "        + \"_\"+str(inflation_factor) or Cluster_out+\"_KO_ID_S\"\n",
    "            + str(threshold_score)+\"_\"+str(inflation_factor)) in file_list:\n",
    "        print(\"Please, set other name of output.\")\n",
    "        sys.exit(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "Check_File(\"results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 24.Read_Equal_BBH(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Read_Equal_BBH(path):\n",
    "    \"Read_Equal BBH by user path Blast Best Hit\"\n",
    "    global threshold_score\n",
    "\n",
    "    with open(path+\"_oneway_threshold_best_hit_Score\"\n",
    "              + str(threshold_score), 'r') as equal_RBH:\n",
    "        for j in equal_RBH:\n",
    "            split_data = j.split()\n",
    "            split_data[2] = int(split_data[2])\n",
    "            equal_BBH_data.append(split_data)\n",
    "            equal_BBH_data_dic[split_data[0]] = split_data[1:]\n",
    "    try:\n",
    "        with open(path+\"_second_oneway_threshold_best_hit_Score\"\n",
    "                  + str(threshold_score), 'r') as second_equal_RBH:\n",
    "            for j in second_equal_RBH:\n",
    "                split_data = j.split()\n",
    "                split_data[2] = int(split_data[2])\n",
    "                second_equal_BBH_data.append(split_data)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 25. Read_Unequal_BBH(path):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Read_Unequal_BBH(path):\n",
    "    \"Read unequal BBH path passed by User\"\n",
    "    with open(path+\"_oneway_threshold_best_hit_Score\"\n",
    "              + str(threshold_score), 'r') as unequal_RBH:\n",
    "        for j in unequal_RBH:\n",
    "            split_data = j.split()\n",
    "            split_data[2] = int(split_data[2])\n",
    "            unequal_BBH_data.append(split_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Main Program Testing\n",
    "`************* No Function below **************************`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. BLASTP. \n",
      "2. BLASTP using precalculated data. \n",
      "3. Clustering.\n",
      "\n",
      ">> Select a mode or modes (1 or 2 or 1 3 or 2 3): 3\n",
      "1. A\n",
      "2. AAE\n",
      "3. C\n",
      "4. CAC\n",
      "5. ECO\n",
      "6. ECU\n",
      "7. HIN\n",
      "8. Log\n",
      "9. chicken.faa\n",
      "10. chimp.faa\n",
      "11. dog.faa\n",
      ">> Select Genomes to detect Orthologs(e.g. 1 2 3 4 5 or 1-5) : 1 3\n",
      "A C BLOcks SUbstitution Matrix (BLOSUM) is a Substitution matrix used for sequence alignment of Proteins\n",
      "\n",
      "1. BLOSUM45 :-For more distantly related Proteins alignment DataBase\n",
      "2. BLOSUM62 :- MidRange Seq with more than 62%similarity         \n",
      "3. BLOSUM82 :- More related Proteins\n",
      "Other Keys to exit the Program -- Quit\n",
      "\n",
      "Enter a matrix number: 1\n",
      "You can use 12 processors. \n",
      "If you input >2, The Program will run a parallel--Enter the number of CPU you want to use :2\n",
      "Enter the inflation factor to cluster10\n",
      "Set the name of Clustering output :cluster_out\n"
     ]
    }
   ],
   "source": [
    "#if not sys.argv[1:]\n",
    "import sys\n",
    "import multiprocessing\n",
    "\n",
    "# If Program not Passed with Parameter\n",
    " # if Not verified Conflict arise for local and global Variable\n",
    "print (\"1. BLASTP. \\n2. BLASTP using precalculated data. \\n3. Clustering.\\n\")\n",
    "mode = input(\">> Select a mode or modes (1 or 2 or 1 3 or 2 3): \") \n",
    "selected_species_dic, backward_selected_species_dic, number_i = Read_Species(1)\n",
    "selected_number = input(\">> Select Genomes to detect Orthologs(e.g. 1 2 3 4 5 or 1-5) : \")\n",
    "\n",
    "if selected_number.find(\"-\")>0:\n",
    "    SN = selected_number.split(\"-\")\n",
    "    if int(SN[-1])>number_i:\n",
    "        print(\"Your input must be less than\" , number_i)\n",
    "        sys.exit(2)\n",
    "    else:\n",
    "        user_selected_number = range(int(SN[0]),int(SN[-1])+1)\n",
    "        print(user_selected_number)\n",
    "        for j in user_selected_number:\n",
    "            print(selected_species_dic[j],end=\" \")\n",
    "        print(\"Are Selected\")\n",
    "else:\n",
    "    user_selected_number = sorted(set([int(read_species) for read_species in selected_number.split()]))\n",
    "    if int(user_selected_number[-1])>number_i:\n",
    "        print (\"\\nWrongInput\\nInput must be less than\",number_i)\n",
    "        sys.exit(2)\n",
    "    else:\n",
    "        for j in user_selected_number:\n",
    "            print(selected_species_dic[j], end =\" \")\n",
    "\n",
    "blastp_matrix = Matrix_Name()\n",
    "cpu_count = int(input(\"You can use %s processors. \\nIf you input >2, The Program will run a parallel--\"\\\n",
    "                      %multiprocessing.cpu_count()+\"Enter the number of CPU you want to use :\"))\n",
    "if \"3\" in mode:\n",
    "    inflation_factor = input(\"Enter the inflation factor to cluster\")\n",
    "    Cluster_out = input(\"Set the name of Clustering output :\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check the File or Path\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'start_time_OBH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-978e33afad88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mDel_File\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"query*\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mfinish_time_OBH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mblastp_time_log\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinish_time_OBH\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time_OBH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"BLASTP searches + forward best Hit + backwardbest hit took %f minutes\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mblastp_time_log\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'start_time_OBH' is not defined"
     ]
    }
   ],
   "source": [
    "if \"1\" in  mode:\n",
    "    backward_best_hit_work_list = Oneway_Threshold_Best_Hit(mode)\n",
    "    pool = multiprocessing.Pool(cpu_count)\n",
    "    results = pool.map(Backward_Best_Hit, backward_best_hit_work_list)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "elif \"2\" in mode:\n",
    "    used_precalculated_data_list = []\n",
    "    new_calculated_data_list = []\n",
    "    precalculated_data_list = glob.glob(Blastp_data+\"*oneway_threshold_best_hit_S\"+str(threshold_score))\n",
    "    print(precalculated_data_list)\n",
    "    backward_best_hit_work_list = Oneway_Threshold_Best_Hit(mode)\n",
    "    \n",
    "    if not backward_best_hit_work_list ==[]:\n",
    "        #If backward_best_hit_work_list is an empty list, pool instance can't finish the work.\n",
    "        pool = multiprocessing.Pool(cpu_count)\n",
    "        results = pool.map(Backward_Best_Hit, backward_best_hit_work_list)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    else:\n",
    "        results = [0,0]\n",
    "Del_File(\"./\",\"query*\")\n",
    "finish_time_OBH = time.time()\n",
    "blastp_time_log = float(((finish_time_OBH - start_time_OBH)/60))\n",
    "print(\"BLASTP searches + forward best Hit + backwardbest hit took %f minutes\"%blastp_time_log)\n",
    "\n",
    "with open(Log_file_name , \"a\") as log:\n",
    "    log.write(\"Backward_Best_Hit took \"+str(max(results))+\" minutes\\n\")\n",
    "    log.write(\"BLASTP + Best_Hit + backward_best_hit searches took\"+ str(blastp_time_log)+\" minutes\\n\")\n",
    "if \"3\" in mode:\n",
    "    start_time_clustering = time.time()\n",
    "    #generate matrix calculate the matrix using MCL algorithm and cluster the Ortholog\n",
    "    \n",
    "    print(\"\\n >>> Start MCL algorithm and Clustering ortholog <<<\")\n",
    "    equal_BBH_data = []\n",
    "    unequal_BBH_data = []\n",
    "    equal_BBH_data_dic = {}\n",
    "    second_equal_BBH_data = []\n",
    "    results = que.Queue()\n",
    "    tasks = queue.Queue()\n",
    "    cluster_count = 1\n",
    "    ortholog_count = 0\n",
    "    gene_id_dic = {}\n",
    "    \n",
    "    with open(\"myva=gb\",\"r\") as id_read:\n",
    "        #myvba=gb is a database\n",
    "        for i in id_read:\n",
    "            gene_name,gene_id = i.split()\n",
    "            gene_id_dic[gene_id.replace(\"\\n\",\"\")] = gene_name # remove '\\n'\n",
    "            \n",
    "        if \"1\" in mode:\n",
    "            for i in user_selected_number:\n",
    "                for k in user_selected_number:\n",
    "                    if k<i:\n",
    "                        pass\n",
    "                    elif i ==k:\n",
    "                        Read_Equal_BBH(Score_file+selected_species_dic[i]+\"_\"+selected_species_dic[k])\n",
    "                    elif i !=k:\n",
    "                        Read_Unequal_BBH(Score_file+selected_species_dic[i]+\"_\"+selected_species_dic[k])\n",
    "        elif \"2\" in mode:\n",
    "            for used_data in used_precalculated_data_list:\n",
    "                first,second = used_data.split(\"_\")\n",
    "                if first == second:\n",
    "                    Read_Equal_BBH(Blastp_data+used-data)\n",
    "                elif first != second:\n",
    "                    Read_Unequal_BBH(Blastp_data+used_data)\n",
    "            for new_data in new_calculated_data_list:\n",
    "                first,second = new_data.split(\"_\")\n",
    "                if first== second:\n",
    "                    Read_Equal_BBH(Score_file+new_data)\n",
    "                elif first != second:\n",
    "                    Read_Unequal_BBH(Score_file+new_data)\n",
    "        matched_BBH_data = []\n",
    "        matched_BBH_element_data_set = []\n",
    "        \n",
    "        for unequal_RBH_element in unequal_BBH_data:\n",
    "            Matching_BBH(unequal_RBH_element)\n",
    "            temp_results_list = []\n",
    "            if results._qsize() !=0: #return the number of results as Queue.\n",
    "                while not results.empty():\n",
    "                    get_results = results.get()\n",
    "                    temp_results_list.append(get_results)\n",
    "                matched_BBH_data.append(temp_results_list)\n",
    "        #bar = bar(\"Processing\", max= len(matched_BBH_data))\n",
    "        #bar = bar(\"Processing\", max= len(matched_BBH_data)) #Not Supported in Python 3\n",
    "        #for data in matched_BBH_data:\n",
    "        #    Generating_Matrix_Clustering_Ortholog(data, bar)\n",
    "        #bar.finish()\n",
    "        finish_time_clustering = time.time()\n",
    "        mcl_time_log = float((finish_time_clustering - start_time_clustering)/60)\n",
    "        remark_time_log = float((finish_time_clustering- start_time_OBH)/60)\n",
    "        print(\"MCL algorithm and Ortholog Clustering took %.2f minutes\"%remark_time_log)\n",
    "        \n",
    "        if \"3\" in mode:\n",
    "            with open(Log_file_name,\"a\") as log:\n",
    "                log.write(\"Ortholog Count: \"+str(ortholog_count)+\",\"+\"Cluster count: \"+ str(cluster_count-1)+\"\\n\")\n",
    "                log.write(\"MCL algorithm and Ortholog Clustering took \"+str(mcl_time_log)+\"minutes\\n\")\n",
    "                log.write(\"xxx Program took \"+str(remark_time_log)+\"minutes\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
